{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "from COTR.models.pl_cotr import Baseline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "debug = torch.load('debug.pth')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "batch = debug['batch']\n",
    "pred = debug['predict']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "batch.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['base_img', 'aug_imgs', 'target_corrs', 'target_mask', 'base_img_idx', 'aug_img_idx'])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "pred.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['pred_corr_volum', 'ref_emb', 'aug_emb', 'corr_loss'])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "pred['pred_corr_volum'].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([72, 16, 16, 16, 16])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "pred_corrs = pred['pred_corr_volum']\n",
    "pred_corrs[0].view([16*16, -1]).max(dim=-1).values"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.0278, 0.0318, 0.0196, 0.0000, 0.0553, 0.0603, 0.0000, 0.0500, 0.0486,\n",
       "        0.0045, 0.0059, 0.0861, 0.0331, 0.0680, 0.0000, 0.0000, 0.0084, 0.0322,\n",
       "        0.0000, 0.0011, 0.0302, 0.0168, 0.0014, 0.0446, 0.0243, 0.0378, 0.0351,\n",
       "        0.0440, 0.0000, 0.0284, 0.0000, 0.0000, 0.0000, 0.0050, 0.0000, 0.0354,\n",
       "        0.0464, 0.0578, 0.0000, 0.0000, 0.0040, 0.0000, 0.0000, 0.0619, 0.0000,\n",
       "        0.0350, 0.0593, 0.0554, 0.0023, 0.0000, 0.0000, 0.0328, 0.0766, 0.0000,\n",
       "        0.0689, 0.0442, 0.0048, 0.0481, 0.0000, 0.0106, 0.0235, 0.0000, 0.0261,\n",
       "        0.0335, 0.0374, 0.0285, 0.0101, 0.0203, 0.0014, 0.0000, 0.0141, 0.0773,\n",
       "        0.0295, 0.0000, 0.0616, 0.0000, 0.0124, 0.0184, 0.0221, 0.0255, 0.0000,\n",
       "        0.0334, 0.0478, 0.0498, 0.0199, 0.0246, 0.0263, 0.0534, 0.0200, 0.0396,\n",
       "        0.0334, 0.0309, 0.0106, 0.0444, 0.0411, 0.0246, 0.0000, 0.0000, 0.0000,\n",
       "        0.0125, 0.0279, 0.0171, 0.0372, 0.0522, 0.0345, 0.0048, 0.0239, 0.0364,\n",
       "        0.0348, 0.0000, 0.0424, 0.0117, 0.0140, 0.0372, 0.0217, 0.0000, 0.0179,\n",
       "        0.0303, 0.0000, 0.0203, 0.0737, 0.0000, 0.0455, 0.0614, 0.0000, 0.0000,\n",
       "        0.0023, 0.0349, 0.0503, 0.0468, 0.0000, 0.0277, 0.0532, 0.0129, 0.0136,\n",
       "        0.0553, 0.0641, 0.0000, 0.0651, 0.0506, 0.0032, 0.0000, 0.0328, 0.0454,\n",
       "        0.0000, 0.0000, 0.0573, 0.0000, 0.0347, 0.0070, 0.0000, 0.0357, 0.0002,\n",
       "        0.0052, 0.0204, 0.0206, 0.0342, 0.0636, 0.0000, 0.0000, 0.0000, 0.0055,\n",
       "        0.0000, 0.0109, 0.0858, 0.0261, 0.0564, 0.0596, 0.0220, 0.0200, 0.0484,\n",
       "        0.0701, 0.0000, 0.0850, 0.0318, 0.0000, 0.0303, 0.0392, 0.0000, 0.0547,\n",
       "        0.0710, 0.0385, 0.0285, 0.0579, 0.0738, 0.0000, 0.0522, 0.0545, 0.0192,\n",
       "        0.0180, 0.0088, 0.0396, 0.0515, 0.0118, 0.0038, 0.0407, 0.0000, 0.0146,\n",
       "        0.0519, 0.0442, 0.0380, 0.0404, 0.0000, 0.0860, 0.0072, 0.0000, 0.0000,\n",
       "        0.0168, 0.0244, 0.0017, 0.0000, 0.0253, 0.0561, 0.0178, 0.0000, 0.0023,\n",
       "        0.0000, 0.0289, 0.0387, 0.0000, 0.0000, 0.0446, 0.0296, 0.0000, 0.0033,\n",
       "        0.0244, 0.0480, 0.0023, 0.0000, 0.0423, 0.0081, 0.0369, 0.0402, 0.0021,\n",
       "        0.0274, 0.0044, 0.0212, 0.0000, 0.0018, 0.0281, 0.0345, 0.0156, 0.0000,\n",
       "        0.0000, 0.0000, 0.0301, 0.0000, 0.0000, 0.0284, 0.0075, 0.0143, 0.0065,\n",
       "        0.0000, 0.0293, 0.0000, 0.0000])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "model = Baseline.load_from_checkpoint('checkpoints/baseline/lightning_logs/version_12/checkpoints/epoch=103-step=51999.ckpt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "ckpt = torch.load('checkpoints/baseline/lightning_logs/version_12/checkpoints/epoch=103-step=51999.ckpt')\n",
    "st = ckpt['state_dict']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "model = Baseline(embed_dim=256, num_classes=1000, partial_fc=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "model.load_state_dict(torch.load('1250-step.pth'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "pred = torch.load('1250-emb.pth')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "pred.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "pred"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-6.2387e-04,  4.4615e-03, -2.8122e-02, -4.1100e-03, -8.3522e-03,\n",
       "          2.0593e-03,  6.6530e-03,  3.5419e-03,  2.3051e-02,  4.9215e-03,\n",
       "          1.2610e-02, -4.2305e-03,  1.5671e-02, -6.9876e-03, -6.3740e-03,\n",
       "         -4.4348e-03,  2.7904e-03,  9.7190e-03, -2.5585e-03, -2.3342e-05,\n",
       "         -1.4082e-02, -3.6896e-03, -2.5564e-02, -1.7033e-02, -7.8566e-03,\n",
       "         -7.3100e-03, -3.6839e-03, -6.4455e-03, -1.5738e-02,  1.4755e-02,\n",
       "          7.3263e-03,  1.5184e-02,  5.7474e-03, -1.4470e-02, -1.7960e-02,\n",
       "          7.0409e-03, -2.7325e-02,  1.7590e-02, -4.2951e-03, -6.2063e-03,\n",
       "         -5.3351e-03, -3.6285e-03,  3.0557e-03, -7.5411e-03,  1.6104e-02,\n",
       "          7.4454e-05, -4.6136e-03,  6.6063e-03,  1.5514e-02,  7.9274e-03,\n",
       "          1.1412e-02,  1.3632e-03, -3.3163e-03, -8.0841e-03, -9.3262e-03,\n",
       "          2.6317e-03, -7.9723e-03, -8.8808e-03,  6.1286e-03,  1.5282e-02,\n",
       "          1.4448e-02, -1.4051e-02, -2.6687e-03,  5.1912e-03, -4.3421e-03,\n",
       "         -1.0494e-02,  1.9260e-02, -1.3815e-02,  2.2528e-03, -6.2389e-03,\n",
       "         -7.9506e-03,  2.1126e-02,  4.1679e-03, -1.0402e-02,  9.0263e-03,\n",
       "         -1.7579e-02, -5.2424e-03, -3.4519e-02, -1.5526e-02,  1.4711e-02,\n",
       "          1.6095e-02,  8.0707e-03,  6.0926e-03,  3.7227e-03, -1.5567e-02,\n",
       "         -9.7426e-03,  2.2947e-02, -9.2236e-04,  1.8093e-02, -2.0479e-02,\n",
       "          2.2349e-02,  1.4998e-02, -2.1511e-03, -8.2211e-03,  3.3254e-03,\n",
       "          3.0408e-03, -2.2901e-02,  4.6980e-03,  5.4023e-03,  2.3537e-02,\n",
       "          1.7193e-03, -1.5273e-02, -7.8232e-03,  2.4396e-02,  1.4670e-02,\n",
       "          8.0040e-03, -7.2779e-03,  1.9737e-02,  7.8015e-03, -1.8512e-02,\n",
       "         -3.8742e-03, -7.0953e-04, -4.5869e-04,  1.8813e-02,  6.9438e-03,\n",
       "         -6.4585e-03,  5.3325e-03,  1.5089e-02,  3.8053e-03,  1.0290e-02,\n",
       "          2.6519e-04, -9.6644e-03, -5.5877e-03,  1.6612e-02, -4.0835e-03,\n",
       "          1.0443e-03, -1.8395e-02,  1.6289e-02,  1.2744e-02, -6.6302e-03,\n",
       "          5.5165e-03,  1.3590e-02, -1.0205e-02,  6.5264e-03,  1.1852e-02,\n",
       "         -1.3124e-02,  4.0557e-03, -4.1225e-03,  7.8036e-03, -2.3496e-02,\n",
       "         -6.8836e-03, -2.1869e-04,  8.0538e-03,  1.0353e-02,  2.1005e-02,\n",
       "          7.9954e-03,  8.3037e-03,  9.6308e-03,  1.1837e-02, -1.1890e-02,\n",
       "         -4.7040e-03,  7.9826e-04, -2.7933e-03,  1.5790e-02,  7.8944e-03,\n",
       "         -1.0407e-02,  7.7569e-03,  3.3344e-03, -1.0922e-02,  6.2902e-04,\n",
       "          1.7704e-02,  3.0801e-03, -8.1739e-03,  7.4240e-03,  1.0733e-02,\n",
       "          4.5743e-03, -1.2188e-02,  7.3091e-04, -5.2586e-03, -2.2210e-02,\n",
       "          1.2476e-03,  6.0083e-03, -7.6598e-03,  4.9013e-03,  2.4330e-03,\n",
       "         -2.1120e-02,  3.9138e-03,  2.0459e-03, -7.0019e-03, -1.3478e-02,\n",
       "         -5.2937e-03, -3.2602e-03, -1.5069e-03,  1.5142e-02,  4.3125e-04,\n",
       "         -7.0104e-03, -1.9451e-02, -1.4561e-02,  3.8240e-02, -1.6811e-02,\n",
       "          2.3155e-02, -1.2976e-02, -3.8348e-03, -1.9045e-02, -7.3081e-03,\n",
       "         -1.2553e-02,  1.6056e-02, -9.7813e-04,  2.5886e-03,  2.7596e-02,\n",
       "         -1.3158e-02, -8.6605e-03, -6.9892e-03, -9.6226e-03, -7.9873e-05,\n",
       "         -1.7871e-02,  1.6566e-03, -1.9588e-03,  7.5366e-03, -1.2359e-02,\n",
       "          2.0572e-03, -1.0871e-04,  1.0246e-02,  9.2025e-03,  8.5972e-03,\n",
       "          2.0992e-02, -5.0609e-03, -1.5952e-03,  9.6154e-03,  1.8288e-03,\n",
       "          2.1831e-02, -2.4559e-02,  1.6559e-02,  3.5903e-03, -4.5202e-03,\n",
       "          1.4194e-02,  1.5737e-02, -4.3930e-03, -1.1754e-03, -2.0547e-02,\n",
       "         -1.6547e-02, -2.1488e-03,  1.8222e-04,  2.0129e-03,  1.2869e-02,\n",
       "          1.5846e-03,  1.4052e-03,  1.1569e-02,  1.8127e-02,  5.9357e-04,\n",
       "          1.0435e-02, -4.5936e-03, -2.1278e-02, -3.0024e-02,  4.0256e-03,\n",
       "         -1.8114e-02, -8.5353e-03,  9.5295e-04,  2.3766e-02,  1.2540e-02,\n",
       "          3.5420e-03,  6.3339e-03, -2.2125e-02,  4.6771e-03,  3.1065e-03,\n",
       "          4.4415e-03]], device='cuda:0', requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "pred_2 = model(torch.ones([1, 3, 256, 256]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "torch.abs(pred_2[1].cpu() - pred.cpu()).max()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(3.7500e-05, grad_fn=<MaxBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "pred_2[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-6.2313e-04,  4.4342e-03, -2.8121e-02, -4.1138e-03, -8.3677e-03,\n",
       "          2.0415e-03,  6.6446e-03,  3.5463e-03,  2.3054e-02,  4.9364e-03,\n",
       "          1.2605e-02, -4.2331e-03,  1.5668e-02, -6.9865e-03, -6.3663e-03,\n",
       "         -4.4305e-03,  2.7954e-03,  9.7187e-03, -2.5802e-03, -3.8778e-05,\n",
       "         -1.4067e-02, -3.6857e-03, -2.5577e-02, -1.7037e-02, -7.8505e-03,\n",
       "         -7.3387e-03, -3.6796e-03, -6.4506e-03, -1.5744e-02,  1.4750e-02,\n",
       "          7.3254e-03,  1.5171e-02,  5.7450e-03, -1.4475e-02, -1.7959e-02,\n",
       "          7.0432e-03, -2.7333e-02,  1.7593e-02, -4.2900e-03, -6.2241e-03,\n",
       "         -5.3433e-03, -3.6339e-03,  3.0715e-03, -7.5231e-03,  1.6092e-02,\n",
       "          8.0585e-05, -4.6116e-03,  6.5899e-03,  1.5512e-02,  7.9371e-03,\n",
       "          1.1411e-02,  1.3556e-03, -3.3051e-03, -8.0950e-03, -9.3317e-03,\n",
       "          2.6284e-03, -7.9583e-03, -8.8797e-03,  6.1268e-03,  1.5296e-02,\n",
       "          1.4448e-02, -1.4054e-02, -2.6520e-03,  5.1972e-03, -4.3457e-03,\n",
       "         -1.0500e-02,  1.9257e-02, -1.3835e-02,  2.2550e-03, -6.2459e-03,\n",
       "         -7.9524e-03,  2.1123e-02,  4.1662e-03, -1.0392e-02,  9.0380e-03,\n",
       "         -1.7575e-02, -5.2319e-03, -3.4515e-02, -1.5543e-02,  1.4729e-02,\n",
       "          1.6089e-02,  8.1082e-03,  6.0857e-03,  3.7257e-03, -1.5565e-02,\n",
       "         -9.7429e-03,  2.2940e-02, -9.1350e-04,  1.8122e-02, -2.0471e-02,\n",
       "          2.2366e-02,  1.5007e-02, -2.1347e-03, -8.2119e-03,  3.3356e-03,\n",
       "          3.0305e-03, -2.2887e-02,  4.7231e-03,  5.4203e-03,  2.3556e-02,\n",
       "          1.7138e-03, -1.5273e-02, -7.8298e-03,  2.4406e-02,  1.4678e-02,\n",
       "          8.0099e-03, -7.2871e-03,  1.9744e-02,  7.8039e-03, -1.8519e-02,\n",
       "         -3.8703e-03, -7.1887e-04, -4.4973e-04,  1.8809e-02,  6.9380e-03,\n",
       "         -6.4781e-03,  5.3364e-03,  1.5087e-02,  3.8006e-03,  1.0284e-02,\n",
       "          2.7153e-04, -9.6718e-03, -5.5771e-03,  1.6596e-02, -4.0865e-03,\n",
       "          1.0656e-03, -1.8390e-02,  1.6290e-02,  1.2735e-02, -6.6302e-03,\n",
       "          5.5057e-03,  1.3587e-02, -1.0183e-02,  6.5093e-03,  1.1843e-02,\n",
       "         -1.3126e-02,  4.0554e-03, -4.1266e-03,  7.8083e-03, -2.3486e-02,\n",
       "         -6.8744e-03, -2.2018e-04,  8.0586e-03,  1.0361e-02,  2.1001e-02,\n",
       "          7.9911e-03,  8.3034e-03,  9.6272e-03,  1.1828e-02, -1.1904e-02,\n",
       "         -4.7065e-03,  7.8085e-04, -2.7936e-03,  1.5787e-02,  7.9080e-03,\n",
       "         -1.0420e-02,  7.7625e-03,  3.3248e-03, -1.0912e-02,  6.3905e-04,\n",
       "          1.7701e-02,  3.0909e-03, -8.1659e-03,  7.4304e-03,  1.0735e-02,\n",
       "          4.5664e-03, -1.2188e-02,  7.5309e-04, -5.2639e-03, -2.2210e-02,\n",
       "          1.2484e-03,  6.0207e-03, -7.6628e-03,  4.9057e-03,  2.4312e-03,\n",
       "         -2.1116e-02,  3.9353e-03,  2.0428e-03, -7.0022e-03, -1.3482e-02,\n",
       "         -5.3088e-03, -3.2602e-03, -1.5043e-03,  1.5139e-02,  4.1885e-04,\n",
       "         -7.0098e-03, -1.9444e-02, -1.4546e-02,  3.8246e-02, -1.6823e-02,\n",
       "          2.3141e-02, -1.2987e-02, -3.8369e-03, -1.9060e-02, -7.2952e-03,\n",
       "         -1.2558e-02,  1.6058e-02, -9.8552e-04,  2.6026e-03,  2.7605e-02,\n",
       "         -1.3157e-02, -8.6688e-03, -6.9965e-03, -9.6341e-03, -7.9789e-05,\n",
       "         -1.7859e-02,  1.6540e-03, -1.9514e-03,  7.5421e-03, -1.2346e-02,\n",
       "          2.0592e-03, -1.0177e-04,  1.0242e-02,  9.1911e-03,  8.5906e-03,\n",
       "          2.1005e-02, -5.0647e-03, -1.5940e-03,  9.6255e-03,  1.8161e-03,\n",
       "          2.1796e-02, -2.4570e-02,  1.6587e-02,  3.5724e-03, -4.5023e-03,\n",
       "          1.4197e-02,  1.5730e-02, -4.4085e-03, -1.1656e-03, -2.0563e-02,\n",
       "         -1.6545e-02, -2.1491e-03,  1.7672e-04,  2.0215e-03,  1.2869e-02,\n",
       "          1.5856e-03,  1.3877e-03,  1.1572e-02,  1.8125e-02,  5.8589e-04,\n",
       "          1.0429e-02, -4.5854e-03, -2.1274e-02, -3.0034e-02,  4.0068e-03,\n",
       "         -1.8117e-02, -8.5511e-03,  9.4570e-04,  2.3745e-02,  1.2550e-02,\n",
       "          3.5384e-03,  6.3172e-03, -2.2140e-02,  4.6884e-03,  3.1186e-03,\n",
       "          4.4328e-03]], grad_fn=<MeanBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "ckpt = torch.load('checkpoints/baseline/lightning_logs/version_18/checkpoints/epoch=9-step=1249.ckpt')['state_dict']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "for k, v in model.named_parameters():\n",
    "    d = torch.abs(ckpt[k].cpu() - v.cpu()).sum()\n",
    "    print(k, float(d))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "debug_tensor_data 0.0\n",
      "backbone.conv1.weight 0.0\n",
      "backbone.bn1.weight 0.0\n",
      "backbone.bn1.bias 0.0\n",
      "backbone.layer1.0.conv1.weight 0.0\n",
      "backbone.layer1.0.bn1.weight 0.0\n",
      "backbone.layer1.0.bn1.bias 0.0\n",
      "backbone.layer1.0.conv2.weight 0.0\n",
      "backbone.layer1.0.bn2.weight 0.0\n",
      "backbone.layer1.0.bn2.bias 0.0\n",
      "backbone.layer1.0.conv3.weight 0.0\n",
      "backbone.layer1.0.bn3.weight 0.0\n",
      "backbone.layer1.0.bn3.bias 0.0\n",
      "backbone.layer1.0.downsample.0.weight 0.0\n",
      "backbone.layer1.0.downsample.1.weight 0.0\n",
      "backbone.layer1.0.downsample.1.bias 0.0\n",
      "backbone.layer1.1.conv1.weight 0.0\n",
      "backbone.layer1.1.bn1.weight 0.0\n",
      "backbone.layer1.1.bn1.bias 0.0\n",
      "backbone.layer1.1.conv2.weight 0.0\n",
      "backbone.layer1.1.bn2.weight 0.0\n",
      "backbone.layer1.1.bn2.bias 0.0\n",
      "backbone.layer1.1.conv3.weight 0.0\n",
      "backbone.layer1.1.bn3.weight 0.0\n",
      "backbone.layer1.1.bn3.bias 0.0\n",
      "backbone.layer1.2.conv1.weight 0.0\n",
      "backbone.layer1.2.bn1.weight 0.0\n",
      "backbone.layer1.2.bn1.bias 0.0\n",
      "backbone.layer1.2.conv2.weight 0.0\n",
      "backbone.layer1.2.bn2.weight 0.0\n",
      "backbone.layer1.2.bn2.bias 0.0\n",
      "backbone.layer1.2.conv3.weight 0.0\n",
      "backbone.layer1.2.bn3.weight 0.0\n",
      "backbone.layer1.2.bn3.bias 0.0\n",
      "backbone.layer2.0.conv1.weight 0.0\n",
      "backbone.layer2.0.bn1.weight 0.0\n",
      "backbone.layer2.0.bn1.bias 0.0\n",
      "backbone.layer2.0.conv2.weight 0.0\n",
      "backbone.layer2.0.bn2.weight 0.0\n",
      "backbone.layer2.0.bn2.bias 0.0\n",
      "backbone.layer2.0.conv3.weight 0.0\n",
      "backbone.layer2.0.bn3.weight 0.0\n",
      "backbone.layer2.0.bn3.bias 0.0\n",
      "backbone.layer2.0.downsample.0.weight 0.0\n",
      "backbone.layer2.0.downsample.1.weight 0.0\n",
      "backbone.layer2.0.downsample.1.bias 0.0\n",
      "backbone.layer2.1.conv1.weight 0.0\n",
      "backbone.layer2.1.bn1.weight 0.0\n",
      "backbone.layer2.1.bn1.bias 0.0\n",
      "backbone.layer2.1.conv2.weight 0.0\n",
      "backbone.layer2.1.bn2.weight 0.0\n",
      "backbone.layer2.1.bn2.bias 0.0\n",
      "backbone.layer2.1.conv3.weight 0.0\n",
      "backbone.layer2.1.bn3.weight 0.0\n",
      "backbone.layer2.1.bn3.bias 0.0\n",
      "backbone.layer2.2.conv1.weight 0.0\n",
      "backbone.layer2.2.bn1.weight 0.0\n",
      "backbone.layer2.2.bn1.bias 0.0\n",
      "backbone.layer2.2.conv2.weight 0.0\n",
      "backbone.layer2.2.bn2.weight 0.0\n",
      "backbone.layer2.2.bn2.bias 0.0\n",
      "backbone.layer2.2.conv3.weight 0.0\n",
      "backbone.layer2.2.bn3.weight 0.0\n",
      "backbone.layer2.2.bn3.bias 0.0\n",
      "backbone.layer2.3.conv1.weight 0.0\n",
      "backbone.layer2.3.bn1.weight 0.0\n",
      "backbone.layer2.3.bn1.bias 0.0\n",
      "backbone.layer2.3.conv2.weight 0.0\n",
      "backbone.layer2.3.bn2.weight 0.0\n",
      "backbone.layer2.3.bn2.bias 0.0\n",
      "backbone.layer2.3.conv3.weight 0.0\n",
      "backbone.layer2.3.bn3.weight 0.0\n",
      "backbone.layer2.3.bn3.bias 0.0\n",
      "backbone.layer3.0.conv1.weight 0.0\n",
      "backbone.layer3.0.bn1.weight 0.0\n",
      "backbone.layer3.0.bn1.bias 0.0\n",
      "backbone.layer3.0.conv2.weight 0.0\n",
      "backbone.layer3.0.bn2.weight 0.0\n",
      "backbone.layer3.0.bn2.bias 0.0\n",
      "backbone.layer3.0.conv3.weight 0.0\n",
      "backbone.layer3.0.bn3.weight 0.0\n",
      "backbone.layer3.0.bn3.bias 0.0\n",
      "backbone.layer3.0.downsample.0.weight 0.0\n",
      "backbone.layer3.0.downsample.1.weight 0.0\n",
      "backbone.layer3.0.downsample.1.bias 0.0\n",
      "backbone.layer3.1.conv1.weight 0.0\n",
      "backbone.layer3.1.bn1.weight 0.0\n",
      "backbone.layer3.1.bn1.bias 0.0\n",
      "backbone.layer3.1.conv2.weight 0.0\n",
      "backbone.layer3.1.bn2.weight 0.0\n",
      "backbone.layer3.1.bn2.bias 0.0\n",
      "backbone.layer3.1.conv3.weight 0.0\n",
      "backbone.layer3.1.bn3.weight 0.0\n",
      "backbone.layer3.1.bn3.bias 0.0\n",
      "backbone.layer3.2.conv1.weight 0.0\n",
      "backbone.layer3.2.bn1.weight 0.0\n",
      "backbone.layer3.2.bn1.bias 0.0\n",
      "backbone.layer3.2.conv2.weight 0.0\n",
      "backbone.layer3.2.bn2.weight 0.0\n",
      "backbone.layer3.2.bn2.bias 0.0\n",
      "backbone.layer3.2.conv3.weight 0.0\n",
      "backbone.layer3.2.bn3.weight 0.0\n",
      "backbone.layer3.2.bn3.bias 0.0\n",
      "backbone.layer3.3.conv1.weight 0.0\n",
      "backbone.layer3.3.bn1.weight 0.0\n",
      "backbone.layer3.3.bn1.bias 0.0\n",
      "backbone.layer3.3.conv2.weight 0.0\n",
      "backbone.layer3.3.bn2.weight 0.0\n",
      "backbone.layer3.3.bn2.bias 0.0\n",
      "backbone.layer3.3.conv3.weight 0.0\n",
      "backbone.layer3.3.bn3.weight 0.0\n",
      "backbone.layer3.3.bn3.bias 0.0\n",
      "backbone.layer3.4.conv1.weight 0.0\n",
      "backbone.layer3.4.bn1.weight 0.0\n",
      "backbone.layer3.4.bn1.bias 0.0\n",
      "backbone.layer3.4.conv2.weight 0.0\n",
      "backbone.layer3.4.bn2.weight 0.0\n",
      "backbone.layer3.4.bn2.bias 0.0\n",
      "backbone.layer3.4.conv3.weight 0.0\n",
      "backbone.layer3.4.bn3.weight 0.0\n",
      "backbone.layer3.4.bn3.bias 0.0\n",
      "backbone.layer3.5.conv1.weight 0.0\n",
      "backbone.layer3.5.bn1.weight 0.0\n",
      "backbone.layer3.5.bn1.bias 0.0\n",
      "backbone.layer3.5.conv2.weight 0.0\n",
      "backbone.layer3.5.bn2.weight 0.0\n",
      "backbone.layer3.5.bn2.bias 0.0\n",
      "backbone.layer3.5.conv3.weight 0.0\n",
      "backbone.layer3.5.bn3.weight 0.0\n",
      "backbone.layer3.5.bn3.bias 0.0\n",
      "backbone.layer4.0.conv1.weight 0.0\n",
      "backbone.layer4.0.bn1.weight 0.0\n",
      "backbone.layer4.0.bn1.bias 0.0\n",
      "backbone.layer4.0.conv2.weight 0.0\n",
      "backbone.layer4.0.bn2.weight 0.0\n",
      "backbone.layer4.0.bn2.bias 0.0\n",
      "backbone.layer4.0.conv3.weight 0.0\n",
      "backbone.layer4.0.bn3.weight 0.0\n",
      "backbone.layer4.0.bn3.bias 0.0\n",
      "backbone.layer4.0.downsample.0.weight 0.0\n",
      "backbone.layer4.0.downsample.1.weight 0.0\n",
      "backbone.layer4.0.downsample.1.bias 0.0\n",
      "backbone.layer4.1.conv1.weight 0.0\n",
      "backbone.layer4.1.bn1.weight 0.0\n",
      "backbone.layer4.1.bn1.bias 0.0\n",
      "backbone.layer4.1.conv2.weight 0.0\n",
      "backbone.layer4.1.bn2.weight 0.0\n",
      "backbone.layer4.1.bn2.bias 0.0\n",
      "backbone.layer4.1.conv3.weight 0.0\n",
      "backbone.layer4.1.bn3.weight 0.0\n",
      "backbone.layer4.1.bn3.bias 0.0\n",
      "backbone.layer4.2.conv1.weight 0.0\n",
      "backbone.layer4.2.bn1.weight 0.0\n",
      "backbone.layer4.2.bn1.bias 0.0\n",
      "backbone.layer4.2.conv2.weight 0.0\n",
      "backbone.layer4.2.bn2.weight 0.0\n",
      "backbone.layer4.2.bn2.bias 0.0\n",
      "backbone.layer4.2.conv3.weight 0.0\n",
      "backbone.layer4.2.bn3.weight 0.0\n",
      "backbone.layer4.2.bn3.bias 0.0\n",
      "input_proj.weight 0.0\n",
      "input_proj.bias 0.0\n",
      "arc_fc.cos_m 0.0\n",
      "arc_fc.sin_m 0.0\n",
      "arc_fc.th 0.0\n",
      "arc_fc.mm 0.0\n",
      "arc_fc.fc.weights.weight 0.0\n",
      "val_margin.loss_fn.margin.beta 0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('imgsim': conda)"
  },
  "interpreter": {
   "hash": "b8ccac80dd1372f709810c31b3c78ab78d347a80ff738324ef39009bcbb53b2e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}